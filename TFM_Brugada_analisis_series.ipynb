{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del poder predictivo de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.utils import to_time_series_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"Symptoms_bef_Dg_DIC_wo_vagal\" #variable objetivo\n",
    "n_clusters = 2 #definimos el número de clusters, en este caso son 2, para pacientes sintomáticos y asintomáticos\n",
    "\n",
    "time_series = pd.read_excel(\"./Biomarkers_12leads.xlsx\") #lectura del dataset que contiene las series temporales\n",
    "time_series.fillna(0, inplace=True) # reemplazando los valores faltantes por 0\n",
    "\n",
    "# Lectura del dataset que contiene la etiqueta\n",
    "labels_df = pd.read_excel(\"./dsBiomarkersPlusClinical.xlsx\")[\n",
    "    [\"BH\", TARGET]\n",
    "]\n",
    "y_train = labels_df.groupby(\"BH\").agg(\"mean\") #agrupando el dataset por el identificador de paciente y obteniendo la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_metrics = {} #diccionario para almacenar el score F1 para cada variable\n",
    "\n",
    "features = time_series.columns #obteniendo una lista de todas las variables disponibles\n",
    "features.drop(\"BH\") #eliminando el identificador de paciente de la lista de variables\n",
    "\n",
    "for feature in features: #iterando por cada variable disponible para obtener la métrica F1 entrenando un modelo con cada una\n",
    "    time_series_list = [] #definiendo una lista para almacenar las series temporales\n",
    "\n",
    "    for bh in y_train.index: #iterando por cada uno de los pacientes\n",
    "        #para cada paciente se almacena la serie temporal de la variable en la lista time_series_list\n",
    "        time_series_list.append(\n",
    "            time_series[time_series[\"BH\"] == bh][feature].to_numpy()\n",
    "        )\n",
    "\n",
    "    time_series_array = to_time_series_dataset(np.array(time_series_list)) #transformando la lista de series temporales de los pacientes en un array y luego en un dataset de series temporales\n",
    "\n",
    "    X_train = TimeSeriesScalerMeanVariance().fit_transform(time_series_array) #escalando las series temporales de los pacientes con la técnica de TimeSeriesScalerMeanVariance\n",
    "\n",
    "    ## DTW dinamic time warping\n",
    "    ts_km = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", verbose=False) #creamos un modelo para clusterización de series temporales TimeSeriesKMeans\n",
    "    ts_km.fit(X_train, y_train[TARGET]) #entrenamos un modelo con las series temporales escaladas de la variable\n",
    "\n",
    "    cluster_assignments = ts_km.labels_ #obtenemos los resultados de la clasificación realizada por el modelo\n",
    "\n",
    "    F1_metrics[feature] = f1_score(y_train[TARGET], cluster_assignments) #obtenemos el score F1 de la clasificación realizada con la variable y guardamos el resultado en el diccionario junto al nombre de la variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_metrics #el diccionario contiene las variables disónibles junto al score F1 obtenido del modelo entrenado sólo con dicha variable, la métrica muestra el poder predictivo que tiene la misma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráficos de series temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista con las mejores variables\n",
    "best_variables = [\n",
    "    \"ST_0_V5\", #seleccionada\n",
    "    # \"PR_III\",\n",
    "    # \"LP_QRSd_III\",\n",
    "    \"ST_0_I\", #seleccionada\n",
    "    \"LP_LAS_III\", #seleccionada\n",
    "    # \"LP_QRSd_II\",\n",
    "    # \"ST_slope_aVL\",\n",
    "    # \"LP_LAS_V6\",\n",
    "    \"LP_RMS40_V4\", #seleccionada\n",
    "]\n",
    "\n",
    "time_series_list = [] # lista para almacenar las series temporales\n",
    "\n",
    "for bh in y_train.index: # iterando por cada paciente\n",
    "    time_series_list.append(\n",
    "        time_series[time_series[\"BH\"] == bh][best_variables].to_numpy() #agregamos las series temporales de las variables seleccionadas del paciente a la lista\n",
    "    )\n",
    "\n",
    "time_series_array = to_time_series_dataset(np.array(time_series_list)) #transformando la lista de series temporales de los pacientes en un array y luego en un dataset de series temporales\n",
    "\n",
    "X_train = TimeSeriesScalerMeanVariance().fit_transform(time_series_array) #escalando las series temporales de los pacientes con la técnica de TimeSeriesScalerMeanVariance\n",
    "\n",
    "\n",
    "ts_km = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", verbose=False) #creamos un modelo para clusterización de series temporales TimeSeriesKMeans\n",
    "ts_km.fit(X_train, y_train[TARGET]) #entrenamos un modelo con las series temporales escaladas de la variable\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10)) #Creando la figura para el gráfico, con medidas 15*10\n",
    "\n",
    "for yi in range(n_clusters): #Iterando por cada uno de los clusters, para pacientes sintomáticos y asintomáticos\n",
    "    plt.subplot(2, n_clusters, yi + 1) #creamos los subplots, para cada categoría\n",
    "\n",
    "    for xx in X_train[y_train[TARGET] == yi]: #para cada paciente de cada categoría graficamos las series temporales aplanadas con una opacidad de 0.15\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=0.15) \n",
    "\n",
    "    plt.plot(ts_km.cluster_centers_[yi].ravel(), \"r-\") #graficamos en rojo el centroide de los clusters\n",
    "\n",
    "    plt.ylim(-15, 15) # definiendo los límites verticales del gráfico, para que se puedan ver alineados\n",
    "\n",
    "    plt.xlabel(\"Observaciones\") #agregando etiquetas al eje x e y\n",
    "    plt.ylabel(\"Variables\")\n",
    "\n",
    "    if yi == 0: #si el cluster es 0, se agrega el texto ASINTOMÁTICO\n",
    "        plt.text(0.15, 0.95, \"ASINTOMÁTICO\" , transform=plt.gca().transAxes)\n",
    "\n",
    "    elif yi == 1: #si el cluster es 1, se agrega el texto SINTOMÁTICO\n",
    "        plt.text(0.15, 0.95, \"SINTOMÁTICO\" , transform=plt.gca().transAxes)\n",
    "\n",
    "    else: #en cualquier otro caso se agrega el texto ERROR\n",
    "        plt.text(0.15, 0.95, \"ERROR\" , transform=plt.gca().transAxes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
